
@article{kusner_word_2015,
  title = {From {{Word Embeddings To Document Distances}}},
  abstract = {We present the Word Mover's Distance (WMD), a novel distance function between text documents. Our work is based on recent results in word embeddings that learn semantically meaningful representations for words from local cooccurrences in sentences. The WMD distance measures the dissimilarity between two text documents as the minimum amount of distance that the embedded words of one document need to ``travel'' to reach the embedded words of another document. We show that this distance metric can be cast as an instance of the Earth Mover's Distance, a well studied transportation problem for which several highly efficient solvers have been developed. Our metric has no hyperparameters and is straight-forward to implement. Further, we demonstrate on eight real world document classification data sets, in comparison with seven stateof-the-art baselines, that the WMD metric leads to unprecedented low k-nearest neighbor document classification error rates.},
  language = {en},
  author = {Kusner, Matt J and Sun, Yu and Kolkin, Nicholas I and Weinberger, Kilian Q},
  year = {2015},
  pages = {10},
  file = {/home/luka/Zotero/storage/ADFBMSCP/Kusner et al. - From Word Embeddings To Document Distances.pdf}
}

@article{felfernig_constraintbased_,
  title = {Constraint-Based {{Recommender Systems}}: {{Technologies}} and {{Research Issues}}},
  abstract = {Recommender systems support users in identifying products and services in e-commerce and other information-rich environments. Recommendation problems have a long history as a successful AI application area, with substantial interest beginning in the mid1990s, and increasing with the subsequent rise of e-commerce. Recommender systems research long focused on recommending only simple products such as movies or books; constraint-based recommendation now receives increasing attention due to the capability of recommending complex products and services. In this paper, we first introduce a taxonomy of recommendation knowledge sources and algorithmic approaches. We then go on to discuss the most prevalent techniques of constraint-based recommendation and outline open research issues.},
  language = {en},
  author = {Felfernig, A and Burke, R},
  pages = {10},
  file = {/home/luka/Zotero/storage/ZWF8UPXL/Felfernig and Burke - Constraint-based Recommender Systems Technologies.pdf}
}

@inproceedings{abdul_trends_2018,
  address = {{Montreal QC, Canada}},
  title = {Trends and {{Trajectories}} for {{Explainable}}, {{Accountable}} and {{Intelligible Systems}}: {{An HCI Research Agenda}}},
  isbn = {978-1-4503-5620-6},
  shorttitle = {Trends and {{Trajectories}} for {{Explainable}}, {{Accountable}} and {{Intelligible Systems}}},
  abstract = {Advances in artificial intelligence, sensors and big data management have far-reaching societal impacts. As these systems augment our everyday lives, it becomes increasingly important for people to understand them and remain in control. We investigate how HCI researchers can help to develop accountable systems by performing a literature analysis of 289 core papers on explanations and explainable systems, as well as 12,412 citing papers. Using topic modeling, co-occurrence and network analysis, we mapped the research space from diverse domains, such as algorithmic accountability, interpretable machine learning, context-awareness, cognitive psychology, and software learnability. We reveal fading and burgeoning trends in explainable systems, and identify domains that are closely connected or mostly isolated. The time is ripe for the HCI community to ensure that the powerful new autonomous systems have intelligible interfaces built-in. From our results, we propose several implications and directions for future research towards this goal.},
  language = {en},
  booktitle = {Proceedings of the 2018 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}  - {{CHI}} '18},
  publisher = {{ACM Press}},
  doi = {10.1145/3173574.3174156},
  author = {Abdul, Ashraf and Vermeulen, Jo and Wang, Danding and Lim, Brian Y. and Kankanhalli, Mohan},
  year = {2018},
  keywords = {Human Centered},
  pages = {1-18},
  file = {/home/luka/Zotero/storage/U2NWV6ZD/Abdul et al. - 2018 - Trends and Trajectories for Explainable, Accountab.pdf}
}

@article{martalnez_integrative_,
  title = {{{TOWARDS AN INTEGRATIVE THEORETICAL FRAMEWORK OF INTERACTIVE MACHINE LEARNING SYSTEMS}}},
  abstract = {Interactive machine learning (IML) is a learning process in which a user interacts with a system to iteratively define and optimise a model. Although recent years have illustrated the proliferation of IML systems in the fields of Human-Computer Interaction (HCI), Information Systems (IS), and Computer Science (CS), current research results are scattered leading to a lack of integration of existing work on IML. Furthermore, due to diverging functionalities and purposes IML systems can refer to, an uncertainty exists regarding the underlying distinct capabilities that constitute this class of systems. By reviewing extensive IML literature, this paper suggests an integrative theoretical framework for IML systems to address these current impediments. Reviewing 2,879 studies in leading journals and conferences during the years 1966-2018, we found an extensive range of applications areas that have implemented IML systems and the necessity to standardise the evaluation of those systems. Our framework offers an essential step to provide a theoretical foundation to integrate concepts and findings across different fields of research. The main contribution of this paper is organising and structuring the body of knowledge in IML for the advancement of the field. Furthermore, we suggest three opportunities for future IML research. From a practical point of view, our integrative theoretical framework can serve as a reference guide to inform the design and implementation of IML systems.},
  language = {en},
  author = {Mart{\~A}{\L}nez, Miguel Angel Meza and Nadj, Mario and Maedche, Alexander},
  keywords = {Human Centered},
  pages = {20},
  file = {/home/luka/Zotero/storage/J6ABZ7JZ/MartÃŁnez et al. - TOWARDS AN INTEGRATIVE THEORETICAL FRAMEWORK OF IN.pdf}
}

@inproceedings{gillies_humancentred_2016,
  address = {{San Jose, California, USA}},
  title = {Human-{{Centred Machine Learning}}},
  isbn = {978-1-4503-4082-3},
  abstract = {Machine learning is one of the most important and successful techniques in contemporary computer science. It involves the statistical inference of models (such as classifiers) from data. It is often conceived in a very impersonal way, with algorithms working autonomously on passively collected data. However, this viewpoint hides considerable human work of tuning the algorithms, gathering the data, and even deciding what should be modeled in the first place. Examining machine learning from a human-centered perspective includes explicitly recognising this human work, as well as reframing machine learning workflows based on situated human working practices, and exploring the coadaptation of humans and systems. A human-centered understanding of machine learning in human context can lead not only to more usable machine learning tools, but to new ways of framing learning computationally. This workshop will bring together researchers to discuss these issues and suggest future research questions aimed at creating a human-centered approach to machine learning.},
  language = {en},
  booktitle = {Proceedings of the 2016 {{CHI Conference Extended Abstracts}} on {{Human Factors}} in {{Computing Systems}}  - {{CHI EA}} '16},
  publisher = {{ACM Press}},
  doi = {10.1145/2851581.2856492},
  author = {Gillies, Marco and Lee, Bongshin and {d'Alessandro}, Nicolas and Tilmanne, Jo{\"e}lle and Kulesza, Todd and Caramiaux, Baptiste and Fiebrink, Rebecca and Tanaka, Atau and Garcia, J{\'e}r{\'e}mie and Bevilacqua, Fr{\'e}d{\'e}ric and Heloir, Alexis and Nunnari, Fabrizio and Mackay, Wendy and Amershi, Saleema},
  year = {2016},
  pages = {3558-3565},
  file = {/home/luka/Zotero/storage/2Z2KNAKD/Gillies et al. - 2016 - Human-Centred Machine Learning.pdf}
}

@article{resnik_using_1995,
  title = {Using {{Information ContentTtaoxEonvoamluyate Semantic Similarity}} in a},
  abstract = {This paper presents a new measure of semantic similarity in an is-a taxonomy, based on the notion of information content. Experimental evaluation suggests that the measure performs encouragingly well (a correlation of r = 0:79 with a benchmark set of human similarity judgments, with an upper bound of r = 0:90 for human subjects performing the same task), and signi cantly better than the traditional edge counting approach (r = 0:66).},
  language = {en},
  author = {Resnik, Philip},
  month = nov,
  year = {1995},
  pages = {6},
  file = {/home/luka/Zotero/storage/IU4UJHVB/Resnik - Using Information ContentTtaoxEonvoamluyate Semant.pdf}
}

@article{burke_knowledgebased_,
  title = {Knowledge-Based Recommender Systems},
  language = {en},
  author = {Burke, Robin},
  pages = {23},
  file = {/home/luka/Zotero/storage/P5RAL596/Burke - Knowledge-based recommender systems.pdf}
}

@article{zesch_analysis_,
  title = {Analysis of the {{Wikipedia Category Graph}} for {{NLP Applications}}},
  language = {en},
  author = {Zesch, Torsten and Gurevych, Iryna},
  pages = {8},
  file = {/home/luka/Zotero/storage/TIKLD8E9/Zesch and Gurevych - Analysis of the Wikipedia Category Graph for NLP A.pdf}
}

@article{farber_linked_2017,
  title = {Linked Data Quality of {{DBpedia}}, {{Freebase}}, {{OpenCyc}}, {{Wikidata}}, and {{YAGO}}},
  volume = {9},
  issn = {22104968, 15700844},
  abstract = {In recent years, several noteworthy large, cross-domain, and openly available knowledge graphs (KGs) have been created. These include DBpedia, Freebase, OpenCyc, Wikidata, and YAGO. Although extensively in use, these KGs have not been subject to an in-depth comparison so far. In this survey, we provide data quality criteria according to which KGs can be analyzed and analyze and compare the above mentioned KGs. Furthermore, we propose a framework for finding the most suitable KG for a given setting.},
  language = {en},
  number = {1},
  journal = {Semantic Web},
  doi = {10.3233/SW-170275},
  author = {F{\"a}rber, Michael and Bartscherer, Frederic and Menne, Carsten and Rettinger, Achim},
  editor = {Zaveri, Amrapali and Kontokostas, Dimitris and Hellmann, Sebastian and Umbrich, J{\"u}rgen and Zaveri, Amrapali and Kontokostas, Dimitris and Hellmann, Sebastian and Umbrich, J{\"u}rgen},
  month = nov,
  year = {2017},
  pages = {77-129},
  file = {/home/luka/Zotero/storage/WKYKTP9A/Färber et al. - 2017 - Linked data quality of DBpedia, Freebase, OpenCyc,.pdf}
}

@incollection{kowaluk_lca_2005,
  address = {{Berlin, Heidelberg}},
  title = {{{LCA Queries}} in {{Directed Acyclic Graphs}}},
  volume = {3580},
  isbn = {978-3-540-27580-0 978-3-540-31691-6},
  abstract = {We present two methods for finding a lowest common ancestor (LCA) for each pair of vertices of a directed acyclic graph (dag) on n vertices and m edges.},
  language = {en},
  booktitle = {Automata, {{Languages}} and {{Programming}}},
  publisher = {{Springer Berlin Heidelberg}},
  doi = {10.1007/11523468_20},
  author = {Kowaluk, Miroslaw and Lingas, Andrzej},
  editor = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Dough and Vardi, Moshe Y. and Weikum, Gerhard and Caires, Lu{\'i}s and Italiano, Giuseppe F. and Monteiro, Lu{\'i}s and Palamidessi, Catuscia and Yung, Moti},
  year = {2005},
  pages = {241-248},
  file = {/home/luka/Zotero/storage/W29E2727/Kowaluk and Lingas - 2005 - LCA Queries in Directed Acyclic Graphs.pdf}
}

@inproceedings{sun_breaking_2017,
  address = {{Troy, New York, USA}},
  series = {{{WebSci}} '17},
  title = {Breaking {{Cycles In Noisy Hierarchies}}},
  isbn = {978-1-4503-4896-6},
  abstract = {Taxonomy graphs that capture hyponymy or meronymy relationships through directed edges are expected to be acyclic. However, in practice, they may have thousands of cycles, as they are often created in a crowd-sourced way. Since these cycles represent logical fallacies, they need to be removed for many web applications. In this paper, we address the problem of breaking cycles while preserving the logical structure (hierarchy) of a directed graph as much as possible. Existing approaches for this problem either need manual intervention or use heuristics that can critically alter the taxonomy structure. In contrast, our approach infers graph hierarchy using a range of features, including a Bayesian skill rating system and a social agony metric. We also devise several strategies to leverage the inferred hierarchy for removing a small subset of edges to make the graph acyclic. Extensive experiments demonstrate the effectiveness of our approach.},
  booktitle = {Proceedings of the 2017 {{ACM}} on {{Web Science Conference}}},
  publisher = {{ACM}},
  doi = {10.1145/3091478.3091495},
  author = {Sun, Jiankai and Ajwani, Deepak and Nicholson, Patrick K. and Sala, Alessandra and Parthasarathy, Srinivasan},
  year = {2017},
  keywords = {cycle edges,directed acyclic graph,graph hierarchy,social agony,trueskill},
  pages = {151--160},
  file = {/home/luka/Zotero/storage/4VA2CQV9/Sun et al. - 2017 - Breaking Cycles In Noisy Hierarchies.pdf}
}

@article{tassoul_clustering_2007,
  title = {Clustering: {{An Essential Step}} from {{Diverging}} to {{Converging}}},
  volume = {16},
  issn = {1467-8691},
  shorttitle = {Clustering},
  abstract = {Within the context of new product development processes and the Creative Problem Solving (CPS) process, the authors have come to the view that clustering is to be seen as a separate step in the process of diverging and converging. Clustering is generally presented as part of the converging stages, and as such categorized as a selection technique, which in the authors' view does not do justice to this activity. It is about expanding knowledge, about connecting ideas, and connecting ideas to problem statements, functionalities, and values and consequences. It is about building a shared understanding, in other words about `making sense', an essential creative activity in the development of concepts and, although different from a more freewheeling divergent phase, can be as creative and maybe even more so. Four kinds of clusterings are distinguished: object clustering, morphological clustering, functional clustering and gestalt clustering. Object clustering is mainly aimed at categorizing ideas into an overviewable set of groups of ideas. No special connections are being made, other then looking for similarities. Morphological clustering is used to split up a problem into subproblems after which the ideas generated are considered as subsolutions which can then be combined into concepts. Functional clustering is interesting when different approaches can be chosen to answer some question. It permits a more strategic choice to be made. Gestalt clustering is a more synthesis like approach, often with a more metaphoric and artistic stance. Collage is a good example of such clustering. General guidelines for clustering are: use a bottom-up process of emergence; postpone early rationalisations and verbalisations; start grouping ideas on the basis of feeling and intuition; and use metaphoric names to identify clusters.},
  language = {en},
  number = {1},
  journal = {Creativity and Innovation Management},
  doi = {10.1111/j.1467-8691.2007.00413.x},
  author = {Tassoul, Marc and Buijs, Jan},
  year = {2007},
  pages = {16-26},
  file = {/home/luka/Zotero/storage/93GXRBF6/Tassoul and Buijs - 2007 - Clustering An Essential Step from Diverging to Co.pdf;/home/luka/Zotero/storage/R9YKNNDT/j.1467-8691.2007.00413.html}
}

@inproceedings{traverso_gades_2016,
  address = {{Leipzig, Germany}},
  title = {{{GADES}}: {{A Graph}}-Based {{Semantic Similarity Measure}}},
  isbn = {978-1-4503-4752-5},
  shorttitle = {{{GADES}}},
  abstract = {Knowledge graphs encode semantics that describes resources in terms of several aspects, e.g., neighbors, class hierarchies, or node degrees. Assessing relatedness of knowledge graph entities is crucial for several data-driven tasks, e.g., ranking, clustering, or link discovery. However, existing similarity measures consider aspects in isolation when determining entity relatedness. We address the problem of similarity assessment between knowledge graph entities, and devise GADES. GADES relies on aspect similarities and computes a similarity measure as the combination of these similarity values. We empirically evaluate the accuracy of GADES on knowledge graphs from different domains, e.g., proteins, and news. Experiment results indicate that GADES exhibits higher correlation with gold standards than studied existing approaches. Thus, these results suggest that similarity measures should not consider aspects in isolation, but combinations of them to precisely determine relatedness.},
  language = {en},
  booktitle = {Proceedings of the 12th {{International Conference}} on {{Semantic Systems}} - {{SEMANTiCS}} 2016},
  publisher = {{ACM Press}},
  doi = {10.1145/2993318.2993343},
  author = {Traverso, Ignacio and Vidal, Maria-Esther and K{\"a}mpgen, Benedikt and {Sure-Vetter}, York},
  year = {2016},
  pages = {101-104},
  file = {/home/luka/Zotero/storage/XRF8BK5K/Traverso et al. - 2016 - GADES A Graph-based Semantic Similarity Measure.pdf}
}

@article{_aframeworkforsemanticsimilaritymeasurestoenhanceknowledgegraphquality_a,
  title = {{{AFrameworkforSemanticSimilarityMeasurestoenhanceKnowledgeGraphQuality}}},
  language = {en},
  pages = {134},
  file = {/home/luka/Zotero/storage/NGLHDXRV/AFrameworkforSemanticSimilarityMeasurestoenhanceKn.pdf}
}

@article{_aframeworkforsemanticsimilaritymeasurestoenhanceknowledgegraphquality_,
  title = {{{AFrameworkforSemanticSimilarityMeasurestoenhanceKnowledgeGraphQuality}}},
  language = {en},
  pages = {134},
  file = {/home/luka/Zotero/storage/SZI8F5XR/AFrameworkforSemanticSimilarityMeasurestoenhanceKn.pdf}
}

@misc{_enhancing_,
  title = {Enhancing User Creativity: {{Semantic}} Measures for Idea Generation | {{Elsevier Enhanced Reader}}},
  shorttitle = {Enhancing User Creativity},
  language = {en},
  howpublished = {https://reader.elsevier.com/reader/sd/pii/S0950705118301394?token=0A2ADEFF55AAE2E2DA36BD6332A91B07E4172C12130724A5BE2C81204E8C421D6B9ABE546515B542C2DE4C19EE97DDB5},
  doi = {10.1016/j.knosys.2018.03.016},
  file = {/home/luka/Zotero/storage/UN4D9QJK/Enhancing user creativity Semantic measures for i.pdf;/home/luka/Zotero/storage/RX9PIFXA/S0950705118301394.html}
}

@article{pedersen_information_,
  title = {Information {{Content Measures}} of {{Semantic Similarity Perform Better Without Sense}}-{{Tagged Text}}},
  abstract = {This paper presents an empirical comparison of similarity measures for pairs of concepts based on Information Content. It shows that using modest amounts of untagged text to derive Information Content results in higher correlation with human similarity judgments than using the largest available corpus of manually annotated sense\textendash{}tagged text.},
  language = {en},
  author = {Pedersen, Ted},
  pages = {4},
  file = {/home/luka/Zotero/storage/J6GADMGJ/Pedersen - Information Content Measures of Semantic Similarit.pdf}
}

@incollection{malyshev_getting_2018,
  address = {{Cham}},
  title = {Getting the {{Most Out}} of {{Wikidata}}: {{Semantic Technology Usage}} in {{Wikipedia}}'s {{Knowledge Graph}}},
  volume = {11137},
  isbn = {978-3-030-00667-9 978-3-030-00668-6},
  shorttitle = {Getting the {{Most Out}} of {{Wikidata}}},
  abstract = {Wikidata is the collaboratively curated knowledge graph of the Wikimedia Foundation (WMF), and the core project of Wikimedia's data management strategy. A major challenge for bringing Wikidata to its full potential was to provide reliable and powerful services for data sharing and query, and the WMF has chosen to rely on semantic technologies for this purpose. A live SPARQL endpoint, regular RDF dumps, and linked data APIs are now forming the backbone of many uses of Wikidata. We describe this influential use case and its underlying infrastructure, analyse current usage, and share our lessons learned and future plans.},
  language = {en},
  booktitle = {The {{Semantic Web}} \textendash{} {{ISWC}} 2018},
  publisher = {{Springer International Publishing}},
  doi = {10.1007/978-3-030-00668-6_23},
  author = {Malyshev, Stanislav and Kr{\"o}tzsch, Markus and Gonz{\'a}lez, Larry and Gonsior, Julius and Bielefeldt, Adrian},
  editor = {Vrande{\v c}i{\'c}, Denny and Bontcheva, Kalina and {Su{\'a}rez-Figueroa}, Mari Carmen and Presutti, Valentina and Celino, Irene and Sabou, Marta and Kaffee, Lucie-Aim{\'e}e and Simperl, Elena},
  year = {2018},
  pages = {376-394},
  file = {/home/luka/Zotero/storage/NTJRHEZF/Malyshev et al. - 2018 - Getting the Most Out of Wikidata Semantic Technol.pdf}
}

@article{siangliulue_supporting_2017,
  title = {Supporting {{Effective Collective Ideation}} at {{Scale}}},
  copyright = {open},
  issn = {http://nrs.harvard.edu/urn-3:HUL.InstRepos:40046559},
  abstract = {Online collective ideation platforms, such as OpenIDEO or Quirky, have demonstrated the potential of large-scale collective innovation in various domains. However, the users of these platforms face new challenges of leveraging collective contributions. The large number of collected ideas prevents users from making full use of these ideas. Finding inspirations from the ideas involves wading through a sea of possibly mundane and redundant ideas. Synthesizing a few solutions from these ideas takes a lot of time and effort. I argue that leaving users to explore ideas in a haphazard manner is ineffective and can decrease the quality of people's creative output. Prior work in cognitive science and creativity research has also suggested that deliberate exploration of the solution space can improve users' creative output and experience. 
I introduce the concept of an idea map, a computational model of the emerging solution space that enables deliberate exploration interactions: 1) presenting a set of ideas with a controlled level of diversity appropriate to the stage of the creative process and 2) presenting a summary view of the solution space. I describe two scalable crowdsourced methods for generating this computational model. The first method computes the model from responses from small micro-task questions. The second method takes an "integrated crowdsourcing" approach that computes the model from users' natural activities during idea generation. The evaluation of the derived models show that the idea maps from both approaches agree with human judgments of similarities among ideas. I show the application of the idea map concept through experiments and a system called IdeaHound. IdeaHound derives an idea map using the integrated crowdsourcing approach and uses the derived model to guide users' exploration of the solution space. The results of the experiments show that an idea map can inspire people to generate diverse ideas. The integrated activities that enable IdeaHound to collect similarity judgments do not deter users from generating ideas and provide enough information to generate a reliable idea map. I also present a study on the effects of different timings of delivering example ideas on an individual's idea generation. The results demonstrate that an intelligent system can provide inspiration at the right moment by using a computational model that is aware of semantic relationships between ideas. Finally, I demonstrate how to use an idea map to support sensemaking during the solution synthesis and present an empirical study of the effect of presenting a summary view of ideas on people's solution synthesis.},
  language = {en},
  author = {Siangliulue, Kanya (Pao)},
  month = may,
  year = {2017},
  file = {/home/luka/Zotero/storage/W6CJ7JEG/SIANGLIULUE-DISSERTATION-2017.pdf;/home/luka/Zotero/storage/ZY79VB5G/40046559.html}
}

@inproceedings{siangliulue_ideahound_2016,
  address = {{Tokyo, Japan}},
  title = {{{IdeaHound}}: {{Improving Large}}-Scale {{Collaborative Ideation}} with {{Crowd}}-{{Powered Real}}-Time {{Semantic Modeling}}},
  isbn = {978-1-4503-4189-9},
  shorttitle = {{{IdeaHound}}},
  abstract = {Prior work on creativity support tools demonstrates how a computational semantic model of a solution space can enable interventions that substantially improve the number, quality and diversity of ideas. However, automated semantic modeling often falls short when people contribute short text snippets or sketches. Innovation platforms can employ humans to provide semantic judgments to construct a semantic model, but this relies on external workers completing a large number of tedious micro tasks. This requirement threatens both accuracy (external workers may lack expertise and context to make accurate semantic judgments) and scalability (external workers are costly). In this paper, we introduce IDEAHOUND, an ideation system that seamlessly integrates the task of defining semantic relationships among ideas into the primary task of idea generation. The system combines implicit human actions with machine learning to create a computational semantic model of the emerging solution space. The integrated nature of these judgments allows IDEAHOUND to leverage the expertise and efforts of participants who are already motivated to contribute to idea generation, overcoming the issues of scalability inherent to existing approaches. Our results show that participants were equally willing to use (and just as productive using) IDEAHOUND compared to a conventional platform that did not require organizing ideas. Our integrated crowdsourcing approach also creates a more accurate semantic model than an existing crowdsourced approach (performed by external crowds). We demonstrate how this model enables helpful creative interventions: providing diverse inspirational examples, providing similar ideas for a given idea and providing a visual overview of the solution space.},
  language = {en},
  booktitle = {Proceedings of the 29th {{Annual Symposium}} on {{User Interface Software}} and {{Technology}}  - {{UIST}} '16},
  publisher = {{ACM Press}},
  doi = {10.1145/2984511.2984578},
  author = {Siangliulue, Pao and Chan, Joel and Dow, Steven P. and Gajos, Krzysztof Z.},
  year = {2016},
  pages = {609-624},
  file = {/home/luka/Zotero/storage/FS2Q4XQB/Siangliulue et al. - 2016 - IdeaHound Improving Large-scale Collaborative Ide.pdf}
}

@article{atoum_comprehensive_,
  title = {A {{Comprehensive Comparative Study}} of {{Word}} and {{Sentence Similarity Measures}}},
  abstract = {Sentence similarity is considered the basis of many natural language tasks such as information retrieval, question answering and text summarization. The semantic meaning between compared text fragments is based on the words' semantic features and their relationships. This article reviews a set of word and sentence similarity measures and compares them on benchmark datasets. On the studied datasets, results showed that hybrid semantic measures perform better than both knowledge and corpus based measures.},
  language = {en},
  author = {Atoum, Issa and Otoom, Ahmed and Kulathuramaiyer, Narayanan},
  pages = {9},
  file = {/home/luka/Zotero/storage/JFP2MLJX/Atoum et al. - A Comprehensive Comparative Study of Word and Sent.pdf}
}

@misc{_human_,
  title = {Human {{Judgements}} of {{Concept Similarity}}},
  howpublished = {https://www.seas.upenn.edu/\textasciitilde{}hansens/conceptSim/},
  file = {/home/luka/Zotero/storage/T2I8RX89/conceptSim.html}
}

@article{rubenstein_contextual_1965,
  title = {Contextual Correlates of Synonymy},
  volume = {8},
  issn = {00010782},
  language = {en},
  number = {10},
  journal = {Communications of the ACM},
  doi = {10.1145/365628.365657},
  author = {Rubenstein, Herbert and Goodenough, John B.},
  month = oct,
  year = {1965},
  pages = {627-633},
  file = {/home/luka/Zotero/storage/G7ZR59GM/Rubenstein and Goodenough - 1965 - Contextual correlates of synonymy.pdf}
}

@article{mineau_automatic_1995,
  title = {Automatic Structuring of Knowledge Bases by Conceptual Clustering},
  volume = {7},
  issn = {1041-4347},
  abstract = {An important structuring mechanism for knowledge bases is building an inheritance hierarchy of classes based on the content of their knowledge objects. This hierarchy facilitates group-related processing tasks such as answering set queries, discriminating between objects, finding similarities among objects, etc. Building this hierarchy is a difficult task for the knowledge engineer. Conceptual clustering may be used to automate or assist the engineer in the creation of such a classification structure. This article introduces a new conceptual clustering method which addresses the problem of clustering large amounts of structured objects. The conditions under which the method is applicable are discussed.{$<>$}},
  number = {5},
  journal = {IEEE Transactions on Knowledge and Data Engineering},
  doi = {10.1109/69.469834},
  author = {Mineau, G. W. and Godin, R.},
  month = oct,
  year = {1995},
  keywords = {Data structures,automatic knowledge base structuring,Buildings,Calculus,classification structure,Clustering methods,conceptual clustering,deductive databases,group-related processing tasks,Indexing,inheritance hierarchy,knowledge acquisition,Knowledge engineering,knowledge representation,Knowledge representation,Machine learning,Proposals,Structural discs},
  pages = {824-829},
  file = {/home/luka/Zotero/storage/QVNTCF4S/Mineau and Godin - 1995 - Automatic structuring of knowledge bases by concep.pdf;/home/luka/Zotero/storage/KC5YMEX3/469834.html}
}

@article{zhu_computing_2017,
  title = {Computing {{Semantic Similarity}} of {{Concepts}} in {{Knowledge Graphs}}},
  volume = {29},
  issn = {1041-4347},
  abstract = {This paper presents a method for measuring the semantic similarity between concepts in Knowledge Graphs (KGs) such as WordNet and DBpedia. Previous work on semantic similarity methods have focused on either the structure of the semantic network between concepts (e.g., path length and depth), or only on the Information Content (IC) of concepts. We propose a semantic similarity method, namely wpath, to combine these two approaches, using IC to weight the shortest path length between concepts. Conventional corpus-based IC is computed from the distributions of concepts over textual corpus, which is required to prepare a domain corpus containing annotated concepts and has high computational cost. As instances are already extracted from textual corpus and annotated by concepts in KGs, graph-based IC is proposed to compute IC based on the distributions of concepts over instances. Through experiments performed on well known word similarity datasets, we show that the wpath semantic similarity method has produced a statistically significant improvement over other semantic similarity methods. Moreover, in a real category classification evaluation, the wpath method has shown the best performance in terms of accuracy and F score.},
  number = {1},
  journal = {IEEE Transactions on Knowledge and Data Engineering},
  doi = {10.1109/TKDE.2016.2610428},
  author = {Zhu, G. and Iglesias, C. A.},
  month = jan,
  year = {2017},
  keywords = {graph theory,Knowledge engineering,annotated concepts,computational cost,concept computing semantic similarity,concept distribution,concept IC,concept information content,corpus-based IC,DBpedia,graph-based IC,information content,information networks,Integrated circuits,KG,knowledge based systems,Knowledge based systems,knowledge graph,knowledge graphs,Measurement,Motion pictures,semantic network,semantic networks,semantic relatedness,Semantic similarity,semantic Web,Semantics,Taxonomy,textual corpus,word similarity datasets,WordNet,wpath semantic similarity},
  pages = {72-85},
  file = {/home/luka/Zotero/storage/LW63YG9X/Zhu and Iglesias - 2017 - Computing Semantic Similarity of Concepts in Knowl.pdf;/home/luka/Zotero/storage/LRV9EVDU/7572993.html}
}

@inproceedings{ethayarajh_unsupervised_2018,
  address = {{Melbourne, Australia}},
  title = {Unsupervised {{Random Walk Sentence Embeddings}}: {{A Strong}} but {{Simple Baseline}}},
  shorttitle = {Unsupervised {{Random Walk Sentence Embeddings}}},
  abstract = {Using a random walk model of text generation, Arora et al. (2017) proposed a strong baseline for computing sentence embeddings: take a weighted average of word embeddings and modify with SVD. This simple method even outperforms far more complex approaches such as LSTMs on textual similarity tasks. In this paper, we first show that word vector length has a confounding effect on the probability of a sentence being generated in Arora et al.'s model. We propose a random walk model that is robust to this confound, where the probability of word generation is inversely related to the angular distance between the word and sentence embeddings. Our approach beats Arora et al.'s by up to 44.4\% on textual similarity tasks and is competitive with state-of-the-art methods. Unlike Arora et al.'s method, ours requires no hyperparameter tuning, which means it can be used when there is no labelled data.},
  language = {en},
  booktitle = {Proceedings of {{The Third Workshop}} on {{Representation Learning}} for {{NLP}}},
  publisher = {{Association for Computational Linguistics}},
  doi = {10.18653/v1/W18-3012},
  author = {Ethayarajh, Kawin},
  year = {2018},
  pages = {91-100},
  file = {/home/luka/Zotero/storage/HYKVQERQ/Ethayarajh - 2018 - Unsupervised Random Walk Sentence Embeddings A St.pdf}
}

@article{ristoski_rdf2vec_2019,
  title = {{{RDF2Vec}}: {{RDF}} Graph Embeddings and Their Applications},
  volume = {10},
  issn = {22104968, 15700844},
  shorttitle = {{{RDF2Vec}}},
  abstract = {Linked Open Data has been recognized as a valuable source for background information in many data mining and information retrieval tasks. However, most of the existing tools require features in propositional form, i.e., a vector of nominal or numerical features associated with an instance, while Linked Open Data sources are graphs by nature. In this paper, we present RDF2Vec, an approach that uses language modeling approaches for unsupervised feature extraction from sequences of words, and adapts them to RDF graphs. We generate sequences by leveraging local information from graph sub-structures, harvested by Weisfeiler-Lehman Subtree RDF Graph Kernels and graph walks, and learn latent numerical representations of entities in RDF graphs. We evaluate our approach on three different tasks: (i) standard machine-learning tasks (ii) entity and document modeling (iii) content-based recommender systems. The evaluation shows that the proposed entity embeddings outperform existing techniques, and that feature vector representations of general knowledge graphs such as DBpedia and Wikidata can be easily reused for different tasks.},
  language = {en},
  number = {4},
  journal = {Semantic Web},
  doi = {10.3233/SW-180317},
  author = {Ristoski, Petar and Rosati, Jessica and Di Noia, Tommaso and De Leone, Renato and Paulheim, Heiko},
  editor = {Lecue, Freddy},
  month = may,
  year = {2019},
  pages = {721-752},
  file = {/home/luka/Zotero/storage/S87QX23Y/Ristoski et al. - 2019 - RDF2Vec RDF graph embeddings and their applicatio.pdf}
}

@inproceedings{thiel_node_2010,
  address = {{Sydney, Australia}},
  title = {Node {{Similarities}} from {{Spreading Activation}}},
  isbn = {978-1-4244-9131-5},
  abstract = {In this paper we propose two methods to derive two different kinds of node similarities in a network based on their neighborhood. The first similarity measure focuses on the overlap of direct and indirect neighbors. The second similarity compares nodes based on the structure of their possibly also very distant - neighborhoods. Instead of using standard node measures, both similarities are derived from spreading activation patterns over time. Whereas in the first method the activation patterns are directly compared, in the second method the relative change of activation over time is compared. We apply both methods to a real-world graph dataset and discuss the results.},
  language = {en},
  booktitle = {2010 {{IEEE International Conference}} on {{Data Mining}}},
  publisher = {{IEEE}},
  doi = {10.1109/ICDM.2010.108},
  author = {Thiel, Kilian and Berthold, Michael R.},
  month = dec,
  year = {2010},
  pages = {1085-1090},
  file = {/home/luka/Zotero/storage/BMVKEH6X/Thiel und Berthold - 2010 - Node Similarities from Spreading Activation.pdf}
}

@article{harrington_sasknet_2016,
  title = {{{SaskNet}}: {{A Spreading Activation Based Semantic Network}}},
  language = {en},
  author = {Harrington, Brian},
  year = {2016},
  pages = {48},
  file = {/home/luka/Zotero/storage/KH6K4UEI/Harrington - SaskNet A Spreading Activation Based Semantic Net.pdf}
}

@article{crestani_application_1997,
  title = {Application of {{Spreading Activation Techniques}} in {{Information Retrieval}}},
  volume = {11},
  abstract = {This paper surveys the use of Spreading Activation techniques on Semantic Networks in Associative Information Retrieval. The major Spreading Activation models are presented and their applications to IR is surveyed. A number of works in this area are critically analyzed in order to study the relevance of Spreading Activation for associative IR. Key words: spreading activation, information storage and retrieval, semantic networks, associative information retrieval, information processing, knowledge representation.},
  journal = {Artificial Intelligence Review},
  doi = {10.1023/A:1006569829653},
  author = {Crestani, Fabio},
  month = dec,
  year = {1997},
  pages = {453-482},
  file = {/home/luka/Zotero/storage/QIUN66MQ/Crestani - 1997 - Application of Spreading Activation Techniques in .pdf}
}

@inproceedings{nastase_topicdriven_2008,
  address = {{Honolulu, Hawaii}},
  series = {{{EMNLP}} '08},
  title = {Topic-Driven {{Multi}}-Document {{Summarization}} with {{Encyclopedic Knowledge}} and {{Spreading Activation}}},
  abstract = {Information of interest to users is often distributed over a set of documents. Users can specify their request for information as a query/topic -- a set of one or more sentences or questions. Producing a good summary of the relevant information relies on understanding the query and linking it with the associated set of documents. To "understand" the query we expand it using encyclopedic knowledge in Wikipedia. The expanded query is linked with its associated documents through spreading activation in a graph that represents words and their grammatical connections in these documents. The topic expanded words and activated nodes in the graph are used to produce an extractive summary. The method proposed is tested on the DUC summarization data. The system implemented ranks high compared to the participating systems in the DUC competitions, confirming our hypothesis that encyclopedic knowledge is a useful addition to a summarization system.},
  booktitle = {Proceedings of the {{Conference}} on {{Empirical Methods}} in {{Natural Language Processing}}},
  publisher = {{Association for Computational Linguistics}},
  author = {Nastase, Vivi},
  year = {2008},
  pages = {763--772},
  file = {/home/luka/Zotero/storage/LRK8LLED/Nastase - 2008 - Topic-driven Multi-document Summarization with Enc.pdf}
}

@inproceedings{wang_knowledge_2014,
  address = {{Doha, Qatar}},
  title = {Knowledge {{Graph}} and {{Text Jointly Embedding}}},
  abstract = {We examine the embedding approach to reason new relational facts from a largescale knowledge graph and a text corpus. We propose a novel method of jointly embedding entities and words into the same continuous vector space. The embedding process attempts to preserve the relations between entities in the knowledge graph and the concurrences of words in the text corpus. Entity names and Wikipedia anchors are utilized to align the embeddings of entities and words in the same space. Large scale experiments on Freebase and a Wikipedia/NY Times corpus show that jointly embedding brings promising improvement in the accuracy of predicting facts, compared to separately embedding knowledge graphs and text. Particularly, jointly embedding enables the prediction of facts containing entities out of the knowledge graph, which cannot be handled by previous embedding methods. At the same time, concerning the quality of the word embeddings, experiments on the analogical reasoning task show that jointly embedding is comparable to or slightly better than word2vec (Skip-Gram).},
  language = {en},
  booktitle = {Proceedings of the 2014 {{Conference}} on {{Empirical Methods}} in {{Natural Language Processing}} ({{EMNLP}})},
  publisher = {{Association for Computational Linguistics}},
  doi = {10.3115/v1/D14-1167},
  author = {Wang, Zhen and Zhang, Jianwen and Feng, Jianlin and Chen, Zheng},
  year = {2014},
  pages = {1591-1601},
  file = {/home/luka/Zotero/storage/7T9GVWJZ/Wang et al. - 2014 - Knowledge Graph and Text Jointly Embedding.pdf}
}

@article{yao_incorporating_,
  title = {Incorporating {{Knowledge Graph Embeddings}} into {{Topic Modeling}}},
  abstract = {Probabilistic topic models could be used to extract lowdimension topics from document collections. However, such models without any human knowledge often produce topics that are not interpretable. In recent years, a number of knowledge-based topic models have been proposed, but they could not process fact-oriented triple knowledge in knowledge graphs. Knowledge graph embeddings, on the other hand, automatically capture relations between entities in knowledge graphs. In this paper, we propose a novel knowledge-based topic model by incorporating knowledge graph embeddings into topic modeling. By combining latent Dirichlet allocation, a widely used topic model with knowledge encoded by entity vectors, we improve the semantic coherence significantly and capture a better representation of a document in the topic space. Our evaluation results will demonstrate the effectiveness of our method.},
  language = {en},
  author = {Yao, Liang and Zhang, Yin and Wei, Baogang and Jin, Zhe and Zhang, Rui and Zhang, Yangyang and Chen, Qinfei},
  pages = {8},
  file = {/home/luka/Zotero/storage/9LPIGF6W/Yao et al. - Incorporating Knowledge Graph Embeddings into Topi.pdf}
}

@article{schneider_topic_2017,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1710.02650},
  primaryClass = {cs},
  title = {Topic {{Modeling}} Based on {{Keywords}} and {{Context}}},
  abstract = {Current topic models often suffer from discovering topics not matching human intuition, unnatural switching of topics within documents and high computational demands. We address these concerns by proposing a topic model and an inference algorithm based on automatically identifying characteristic keywords for topics. Keywords influence topic-assignments of nearby words. Our algorithm learns (key)word-topic scores and it self-regulates the number of topics. Inference is simple and easily parallelizable. Qualitative analysis yields comparable results to state-of-the-art models (eg. LDA), but with different strengths and weaknesses. Quantitative analysis using 9 datasets shows gains in terms of classification accuracy, PMI score, computational performance and consistency of topic assignments within documents, while most often using less topics.},
  language = {en},
  journal = {arXiv:1710.02650 [cs]},
  author = {Schneider, Johannes},
  month = oct,
  year = {2017},
  keywords = {Computer Science - Computation and Language,Computer Science - Information Retrieval,Computer Science - Machine Learning},
  file = {/home/luka/Zotero/storage/6BN97WT8/Schneider - 2017 - Topic Modeling based on Keywords and Context.pdf},
  annote = {Comment: SIAM International Conference on Data Mining (SDM), 2018}
}

@misc{_chi_,
  title = {{{CHI}} 2019: {{Understanding Ideation Processes}} by Means of {{Semantic Concept Validation}} - {{HCC}} - {{HCC Home}}},
  howpublished = {https://intern.hcc.mi.fu-berlin.de/confluence/pages/viewpage.action?spaceKey=HCC\&title=CHI+2019\%3A+Understanding+Ideation+Processes+by+means+of+Semantic+Concept+Validation\&preview=/33267499/33267863/applying-interactive-concept.pdf},
  file = {/home/luka/Zotero/storage/GS53XZNI/CHI 2019 Understanding Ideation Processes by mean.pdf;/home/luka/Zotero/storage/2YNHUM2S/viewpage.html}
}

@inproceedings{sahoo_novel_2016,
  title = {A Novel Approach to Sentence Clustering},
  abstract = {Sentence clustering is often used as the first step in various information retrieval tasks like automatic text summarization, topic detection and tracking etc. Researchers face difficulty to cluster sentences because a single sentence is less informative compared to document. We present a sentence Feature Based Sentence Clustering, FBSC, which incorporates some sentence level relationship features like transition relationship, anaphoric relationship, and term (word) similarity relationship in association with Markov Clustering Algorithm (MCL) to generate sentence clusters. We observe that Purity of clusters generated by Feature Based Sentence Clustering (FBSC) compared to baseline k-means sentence clustering is better.},
  booktitle = {2016 {{International Conference}} on {{Computing}}, {{Communication}} and {{Automation}} ({{ICCCA}})},
  doi = {10.1109/CCAA.2016.7813697},
  author = {Sahoo, D. and Balabantaray, R.},
  month = apr,
  year = {2016},
  keywords = {anaphoric relationship,automatic text summarization,Automation,clustering,Clustering algorithms,Computational modeling,FBSC,feature based sentence clustering,information retrieval,Information retrieval,information retrieval tasks,Markov clustering algorithm,Markov processes,MCL,pattern clustering,Silicon,term similarity,term similarity relationship,text analysis,Text mining,topic detection,topic tracking,transition relationship,word similarity relationship},
  pages = {1-6},
  file = {/home/luka/Zotero/storage/RRFWXJM5/Sahoo und Balabantaray - 2016 - A novel approach to sentence clustering.pdf;/home/luka/Zotero/storage/IDR84N2P/7813697.html}
}

@inproceedings{coursey_topic_2009,
  address = {{Boulder, Colorado}},
  title = {Topic Identification Using {{Wikipedia}} Graph Centrality},
  abstract = {This paper presents a method for automatic topic identification using a graph-centrality algorithm applied to an encyclopedic graph derived from Wikipedia. When tested on a data set with manually assigned topics, the system is found to significantly improve over a simpler baseline that does not make use of the external encyclopedic knowledge.},
  language = {en},
  booktitle = {Proceedings of {{Human Language Technologies}}: {{The}} 2009 {{Annual Conference}} of the {{North American Chapter}} of the {{Association}} for {{Computational Linguistics}}, {{Companion Volume}}: {{Short Papers}} on - {{NAACL}} '09},
  publisher = {{Association for Computational Linguistics}},
  doi = {10.3115/1620853.1620887},
  author = {Coursey, Kino and Mihalcea, Rada},
  year = {2009},
  pages = {117},
  file = {/home/luka/Zotero/storage/ACVCH236/Coursey und Mihalcea - 2009 - Topic identification using Wikipedia graph central.pdf}
}

@inproceedings{cano_harnessing_2013,
  address = {{Paris, France}},
  title = {Harnessing Linked Knowledge Sources for Topic Classification in Social Media},
  isbn = {978-1-4503-1967-6},
  abstract = {Topic classification (TC) of short text messages offers an effective and fast way to reveal events happening around the world ranging from those related to Disaster (e.g. Sandy hurricane) to those related to Violence (e.g. Egypt revolution). Previous approaches to TC have mostly focused on exploiting individual knowledge sources (KS) (e.g. DBpedia or Freebase) without considering the graph structures that surround concepts present in KSs when detecting the topics of Tweets. In this paper we introduce a novel approach for harnessing such graph structures from multiple linked KSs, by: (i) building a conceptual representation of the KSs, (ii) leveraging contextual information about concepts by exploiting semantic concept graphs, and (iii) providing a principled way for the combination of KSs. Experiments evaluating our TC classifier in the context of Violence detection (VD) and Emergency Responses (ER) show promising results that significantly outperform various baseline models including an approach using a single KS without linked data and an approach using only Tweets.},
  language = {en},
  booktitle = {Proceedings of the 24th {{ACM Conference}} on {{Hypertext}} and {{Social Media}} - {{HT}} '13},
  publisher = {{ACM Press}},
  doi = {10.1145/2481492.2481497},
  author = {Cano, Amparo E. and Varga, Andrea and Rowe, Matthew and Ciravegna, Fabio and He, Yulan},
  year = {2013},
  pages = {41-50},
  file = {/home/luka/Zotero/storage/2A4LW2PX/Cano et al. - 2013 - Harnessing linked knowledge sources for topic clas.pdf}
}

@inproceedings{hu_exploiting_2009,
  address = {{Hong Kong, China}},
  title = {Exploiting Internal and External Semantics for the Clustering of Short Texts Using World Knowledge},
  isbn = {978-1-60558-512-3},
  abstract = {Clustering of short texts, such as snippets, presents great challenges in existing aggregated search techniques due to the problem of data sparseness and the complex semantics of natural language. As short texts do not provide sufficient term co-occurrence information, traditional text representation methods, such as ``bag of words'' model, have several limitations when directly applied to short text tasks. In this paper, we propose a novel framework to improve the performance of short text clustering by exploiting the internal semantics from the original text and external concepts from world knowledge. The proposed method employs a hierarchical three-level structure to tackle the data sparsity problem of original short texts and reconstruct the corresponding feature space with the integration of multiple semantic knowledge bases \textendash{} Wikipedia and WordNet. Empirical evaluation with Reuters and real web dataset demonstrates that our approach is able to achieve significant improvement as compared to the state-of-the-art methods.},
  language = {en},
  booktitle = {Proceeding of the 18th {{ACM}} Conference on {{Information}} and Knowledge Management - {{CIKM}} '09},
  publisher = {{ACM Press}},
  doi = {10.1145/1645953.1646071},
  author = {Hu, Xia and Sun, Nan and Zhang, Chao and Chua, Tat-Seng},
  year = {2009},
  pages = {919},
  file = {/home/luka/Zotero/storage/MWEWHJ9G/Hu et al. - 2009 - Exploiting internal and external semantics for the.pdf}
}

@inproceedings{banerjee_clustering_2007,
  address = {{Amsterdam, The Netherlands}},
  title = {Clustering Short Texts Using Wikipedia},
  isbn = {978-1-59593-597-7},
  abstract = {Subscribers to the popular news or blog feeds (RSS/Atom) often face the problem of information overload as these feed sources usually deliver large number of items periodically. One solution to this problem could be clustering similar items in the feed reader to make the information more manageable for a user. Clustering items at the feed reader end is a challenging task as usually only a small part of the actual article is received through the feed. In this paper, we propose a method of improving the accuracy of clustering short texts by enriching their representation with additional features from Wikipedia. Empirical results indicate that this enriched representation of text items can substantially improve the clustering accuracy when compared to the conventional bag of words representation.},
  language = {en},
  booktitle = {Proceedings of the 30th Annual International {{ACM SIGIR}} Conference on {{Research}} and Development in Information Retrieval - {{SIGIR}} '07},
  publisher = {{ACM Press}},
  doi = {10.1145/1277741.1277909},
  author = {Banerjee, Somnath and Ramanathan, Krishnan and Gupta, Ajay},
  year = {2007},
  pages = {787},
  file = {/home/luka/Zotero/storage/JQD8NJKR/Banerjee et al. - 2007 - Clustering short texts using wikipedia.pdf}
}

@article{jagarlamudi_incorporating_,
  title = {Incorporating {{Lexical Priors}} into {{Topic Models}}},
  abstract = {Topic models have great potential for helping users understand document corpora. This potential is stymied by their purely unsupervised nature, which often leads to topics that are neither entirely meaningful nor effective in extrinsic tasks (Chang et al., 2009). We propose a simple and effective way to guide topic models to learn topics of specific interest to a user. We achieve this by providing sets of seed words that a user believes are representative of the underlying topics in a corpus. Our model uses these seeds to improve both topicword distributions (by biasing topics to produce appropriate seed words) and to improve document-topic distributions (by biasing documents to select topics related to the seed words they contain). Extrinsic evaluation on a document clustering task reveals a significant improvement when using seed information, even over other models that use seed information na\textasciidieresis\i{}vely.},
  language = {en},
  author = {Jagarlamudi, Jagadeesh and Iii, Hal Daume and Udupa, Raghavendra},
  pages = {10},
  file = {/home/luka/Zotero/storage/X47SRW2B/Jagarlamudi et al. - Incorporating Lexical Priors into Topic Models.pdf}
}


