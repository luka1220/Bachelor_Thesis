{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import lda\n",
    "import lda.datasets\n",
    "from nltk.stem import SnowballStemmer\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000 25000\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open('ac2-combined-ideas.json', 'r') as f:\n",
    "    ac1_dict = json.load(f)[\"@graph\"]\n",
    "    content_array = list(map(lambda idea: idea[\"content\"], ac1_dict));\n",
    "\n",
    "with open('patent_25k.csv', 'r') as f:\n",
    "    title = []\n",
    "    content = []\n",
    "    for line in f:\n",
    "        arr = line.split(\"\\t\")\n",
    "        title += [arr[7]]\n",
    "        content += [arr[6]]\n",
    "        \n",
    "print(len(content),len(title))\n",
    "content_array += content\n",
    "#with open('ac2-abstract-ideas.json', 'r') as f:\n",
    "#    ac2_dict = json.load(f)[\"@graph\"]\n",
    "#content_array += list(map(lambda idea: idea[\"content\"], ac2_dict));\n",
    "#print(content_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "englishStemmer=SnowballStemmer(\"english\",  ignore_stopwords=True)\n",
    "content_array = [\" \".join([englishStemmer.stem(x) for x in nltk.word_tokenize(c)]) for c in content_array]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nr_of_sprowords: 318\n",
      "nr_ideas: 25419 vocab: 10530 (25419, 10530)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = CountVectorizer(stop_words=\"english\", max_df=0.1)\n",
    "print(\"nr_of_sprowords:\",len(vectorizer.get_stop_words()))\n",
    "X = vectorizer.fit_transform(content_array)\n",
    "vocab = vectorizer.get_feature_names()\n",
    "print(\"nr_ideas:\",len(content_array),\"vocab:\",len(vocab), X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lda:n_documents: 25419\n",
      "INFO:lda:vocab_size: 10530\n",
      "INFO:lda:n_words: 139493\n",
      "INFO:lda:n_topics: 10\n",
      "INFO:lda:n_iter: 1500\n",
      "WARNING:lda:all zero row in document-term matrix found\n",
      "/usr/local/lib/python3.7/site-packages/lda/utils.py:55: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if sparse and not np.issubdtype(doc_word.dtype, int):\n",
      "INFO:lda:<0> log likelihood: -1614323\n",
      "INFO:lda:<10> log likelihood: -1208382\n",
      "INFO:lda:<20> log likelihood: -1147285\n",
      "INFO:lda:<30> log likelihood: -1121639\n",
      "INFO:lda:<40> log likelihood: -1109925\n",
      "INFO:lda:<50> log likelihood: -1103976\n",
      "INFO:lda:<60> log likelihood: -1098398\n",
      "INFO:lda:<70> log likelihood: -1095122\n",
      "INFO:lda:<80> log likelihood: -1091792\n",
      "INFO:lda:<90> log likelihood: -1089013\n",
      "INFO:lda:<100> log likelihood: -1086425\n",
      "INFO:lda:<110> log likelihood: -1085786\n",
      "INFO:lda:<120> log likelihood: -1083949\n",
      "INFO:lda:<130> log likelihood: -1082653\n",
      "INFO:lda:<140> log likelihood: -1082896\n",
      "INFO:lda:<150> log likelihood: -1081321\n",
      "INFO:lda:<160> log likelihood: -1081482\n",
      "INFO:lda:<170> log likelihood: -1080647\n",
      "INFO:lda:<180> log likelihood: -1080446\n",
      "INFO:lda:<190> log likelihood: -1079548\n",
      "INFO:lda:<200> log likelihood: -1080110\n",
      "INFO:lda:<210> log likelihood: -1079631\n",
      "INFO:lda:<220> log likelihood: -1079205\n",
      "INFO:lda:<230> log likelihood: -1078373\n",
      "INFO:lda:<240> log likelihood: -1079070\n",
      "INFO:lda:<250> log likelihood: -1078875\n",
      "INFO:lda:<260> log likelihood: -1078498\n",
      "INFO:lda:<270> log likelihood: -1078248\n",
      "INFO:lda:<280> log likelihood: -1078793\n",
      "INFO:lda:<290> log likelihood: -1078443\n",
      "INFO:lda:<300> log likelihood: -1078413\n",
      "INFO:lda:<310> log likelihood: -1078099\n",
      "INFO:lda:<320> log likelihood: -1078046\n",
      "INFO:lda:<330> log likelihood: -1077776\n",
      "INFO:lda:<340> log likelihood: -1077815\n",
      "INFO:lda:<350> log likelihood: -1077445\n",
      "INFO:lda:<360> log likelihood: -1077472\n",
      "INFO:lda:<370> log likelihood: -1077821\n",
      "INFO:lda:<380> log likelihood: -1077169\n",
      "INFO:lda:<390> log likelihood: -1076808\n",
      "INFO:lda:<400> log likelihood: -1076751\n",
      "INFO:lda:<410> log likelihood: -1076468\n",
      "INFO:lda:<420> log likelihood: -1076858\n",
      "INFO:lda:<430> log likelihood: -1076481\n",
      "INFO:lda:<440> log likelihood: -1076712\n",
      "INFO:lda:<450> log likelihood: -1076394\n",
      "INFO:lda:<460> log likelihood: -1076424\n",
      "INFO:lda:<470> log likelihood: -1076481\n",
      "INFO:lda:<480> log likelihood: -1076423\n",
      "INFO:lda:<490> log likelihood: -1075966\n",
      "INFO:lda:<500> log likelihood: -1076264\n",
      "INFO:lda:<510> log likelihood: -1076281\n",
      "INFO:lda:<520> log likelihood: -1075772\n",
      "INFO:lda:<530> log likelihood: -1076063\n",
      "INFO:lda:<540> log likelihood: -1076684\n",
      "INFO:lda:<550> log likelihood: -1075789\n",
      "INFO:lda:<560> log likelihood: -1075910\n",
      "INFO:lda:<570> log likelihood: -1076346\n",
      "INFO:lda:<580> log likelihood: -1076457\n",
      "INFO:lda:<590> log likelihood: -1076047\n",
      "INFO:lda:<600> log likelihood: -1075591\n",
      "INFO:lda:<610> log likelihood: -1075951\n",
      "INFO:lda:<620> log likelihood: -1076032\n",
      "INFO:lda:<630> log likelihood: -1076168\n",
      "INFO:lda:<640> log likelihood: -1075838\n",
      "INFO:lda:<650> log likelihood: -1075585\n",
      "INFO:lda:<660> log likelihood: -1075637\n",
      "INFO:lda:<670> log likelihood: -1075752\n",
      "INFO:lda:<680> log likelihood: -1075786\n",
      "INFO:lda:<690> log likelihood: -1075701\n",
      "INFO:lda:<700> log likelihood: -1075837\n",
      "INFO:lda:<710> log likelihood: -1076116\n",
      "INFO:lda:<720> log likelihood: -1075545\n",
      "INFO:lda:<730> log likelihood: -1075815\n",
      "INFO:lda:<740> log likelihood: -1075965\n",
      "INFO:lda:<750> log likelihood: -1075737\n",
      "INFO:lda:<760> log likelihood: -1076461\n",
      "INFO:lda:<770> log likelihood: -1076089\n",
      "INFO:lda:<780> log likelihood: -1075722\n",
      "INFO:lda:<790> log likelihood: -1075628\n",
      "INFO:lda:<800> log likelihood: -1075786\n",
      "INFO:lda:<810> log likelihood: -1075348\n",
      "INFO:lda:<820> log likelihood: -1076089\n",
      "INFO:lda:<830> log likelihood: -1075327\n",
      "INFO:lda:<840> log likelihood: -1075895\n",
      "INFO:lda:<850> log likelihood: -1075875\n",
      "INFO:lda:<860> log likelihood: -1075996\n",
      "INFO:lda:<870> log likelihood: -1075301\n",
      "INFO:lda:<880> log likelihood: -1075867\n",
      "INFO:lda:<890> log likelihood: -1075822\n",
      "INFO:lda:<900> log likelihood: -1075929\n",
      "INFO:lda:<910> log likelihood: -1075506\n",
      "INFO:lda:<920> log likelihood: -1075981\n",
      "INFO:lda:<930> log likelihood: -1076243\n",
      "INFO:lda:<940> log likelihood: -1076039\n",
      "INFO:lda:<950> log likelihood: -1076111\n",
      "INFO:lda:<960> log likelihood: -1076218\n",
      "INFO:lda:<970> log likelihood: -1075739\n",
      "INFO:lda:<980> log likelihood: -1075982\n",
      "INFO:lda:<990> log likelihood: -1075600\n",
      "INFO:lda:<1000> log likelihood: -1075641\n",
      "INFO:lda:<1010> log likelihood: -1075945\n",
      "INFO:lda:<1020> log likelihood: -1075792\n",
      "INFO:lda:<1030> log likelihood: -1075446\n",
      "INFO:lda:<1040> log likelihood: -1075247\n",
      "INFO:lda:<1050> log likelihood: -1075227\n",
      "INFO:lda:<1060> log likelihood: -1075464\n",
      "INFO:lda:<1070> log likelihood: -1075477\n",
      "INFO:lda:<1080> log likelihood: -1075137\n",
      "INFO:lda:<1090> log likelihood: -1075703\n",
      "INFO:lda:<1100> log likelihood: -1075468\n",
      "INFO:lda:<1110> log likelihood: -1075293\n",
      "INFO:lda:<1120> log likelihood: -1075332\n",
      "INFO:lda:<1130> log likelihood: -1075607\n",
      "INFO:lda:<1140> log likelihood: -1075883\n",
      "INFO:lda:<1150> log likelihood: -1075127\n",
      "INFO:lda:<1160> log likelihood: -1075279\n",
      "INFO:lda:<1170> log likelihood: -1075079\n",
      "INFO:lda:<1180> log likelihood: -1075228\n",
      "INFO:lda:<1190> log likelihood: -1075655\n",
      "INFO:lda:<1200> log likelihood: -1074980\n",
      "INFO:lda:<1210> log likelihood: -1075068\n",
      "INFO:lda:<1220> log likelihood: -1075637\n",
      "INFO:lda:<1230> log likelihood: -1075618\n",
      "INFO:lda:<1240> log likelihood: -1075530\n",
      "INFO:lda:<1250> log likelihood: -1075275\n",
      "INFO:lda:<1260> log likelihood: -1075116\n",
      "INFO:lda:<1270> log likelihood: -1075364\n",
      "INFO:lda:<1280> log likelihood: -1074900\n",
      "INFO:lda:<1290> log likelihood: -1075180\n",
      "INFO:lda:<1300> log likelihood: -1075956\n",
      "INFO:lda:<1310> log likelihood: -1075819\n",
      "INFO:lda:<1320> log likelihood: -1075289\n",
      "INFO:lda:<1330> log likelihood: -1075340\n",
      "INFO:lda:<1340> log likelihood: -1075177\n",
      "INFO:lda:<1350> log likelihood: -1075133\n",
      "INFO:lda:<1360> log likelihood: -1075282\n",
      "INFO:lda:<1370> log likelihood: -1075347\n",
      "INFO:lda:<1380> log likelihood: -1075052\n",
      "INFO:lda:<1390> log likelihood: -1075764\n",
      "INFO:lda:<1400> log likelihood: -1075267\n",
      "INFO:lda:<1410> log likelihood: -1075288\n",
      "INFO:lda:<1420> log likelihood: -1074913\n",
      "INFO:lda:<1430> log likelihood: -1075557\n",
      "INFO:lda:<1440> log likelihood: -1075037\n",
      "INFO:lda:<1450> log likelihood: -1074749\n",
      "INFO:lda:<1460> log likelihood: -1075000\n",
      "INFO:lda:<1470> log likelihood: -1075416\n",
      "INFO:lda:<1480> log likelihood: -1074945\n",
      "INFO:lda:<1490> log likelihood: -1075468\n",
      "INFO:lda:<1499> log likelihood: -1075139\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: display semiconductor manufactur light electron structur imag having\n",
      "Topic 1: composit process materi use produc product contain manufactur\n",
      "Topic 2: use composit thereof treatment compound cell treat acid\n",
      "Topic 3: measur optic sensor use detect high magnet imag\n",
      "Topic 4: imag process communic control data inform wireless medium\n",
      "Topic 5: power vehicl control electr circuit drive electron oper\n",
      "Topic 6: data network manag base content comput servic user\n",
      "Topic 7: assembl tool having structur support mechan machin member\n",
      "Topic 8: use detect monitor object technolog track movement vehicl\n",
      "Topic 9: control engin heat air gas valv fluid fuel\n"
     ]
    }
   ],
   "source": [
    "new_model = lda.LDA(n_topics=10, n_iter=1500, random_state=1)\n",
    "new_model.fit(X)  # model.fit_transform(X) is also available\n",
    "topic_word = new_model.topic_word_  # model.components_ also works\n",
    "n_top_words = 8\n",
    "for i, topic_dist in enumerate(topic_word):\n",
    "    topic_words = np.array(vocab)[np.argsort(topic_dist)][:-(n_top_words+1):-1]\n",
    "    print('Topic {}: {}'.format(i, ' '.join(topic_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.68333333 0.18333333 0.01666667]\n",
      "the technolog can be use to monitor air craft . (top topic: [8 9 7])\n",
      "[0.74571429 0.20285714 0.03142857]\n",
      "the devic could be use in a detect manner that is to say that it could be use to predict behavior pattern of say crimin offend , student , to perform research perhap by track the physic live of athlet or top achiev businessman or for compani to isol expect behavior of their employe and how they anticip employe to move during a work day to establish fair and true standard (top topic: [8 6 9])\n",
      "[0.61071429 0.14642857 0.11071429]\n",
      "an applic could be creat for pet owner who have pet who have ran away from home . the applic could be download right onto a person phone . the hand size devic could be put into a collar of a pet , or a chip like devic under the skin . the system would be abl to pin point a pet locat to the direct coordin . (top topic: [8 3 6])\n",
      "[0.7625 0.1375 0.0125]\n",
      "the technolog can assist with traffic manag by analyz and predict pattern . (top topic: [8 6 9])\n",
      "[0.775 0.025 0.025]\n",
      "find live be in a fire or natur disast (top topic: [8 9 7])\n",
      "[0.50714286 0.29285714 0.07857143]\n",
      "could be use in aviat to track aircraft movement in flight to help better calcul effici path to travel in flight (top topic: [8 9 5])\n",
      "[0.63333333 0.18888889 0.07777778]\n",
      "this technolog could be life save for babi who are born prematur . their heart rate , breath pattern , bodi temperatur , oxygen level and so much more could be accur test all day and night . any alarm chang could be report by the artifici intellig . all of the wire could be elimin by this technolog . (top topic: [8 3 7])\n",
      "[0.804 0.164 0.004]\n",
      "i think one thing that i think is very interest to do is if it can analyz movement i think it would me amaz at optim speed and find pattern to help push not only peopl to their fullest potenti but also object . tri to find pattern that human use at max speed and we can further that and our limit would probabl be top . (top topic: [8 6 9])\n",
      "[0.64545455 0.28181818 0.00909091]\n",
      "the technolog can be use to observ the motion of wave in an attempt to explain the rogu wave phenomenon . (top topic: [8 3 9])\n",
      "[0.93571429 0.00714286 0.00714286]\n",
      "it can be use as a home secur devic . it can recogn the peopl and anim movement that are usual insid the home and alert when there is an unfamiliar movement . (top topic: [8 9 7])\n"
     ]
    }
   ],
   "source": [
    "doc_topic = new_model.doc_topic_\n",
    "for i in range(10):\n",
    "    print(np.sort(doc_topic[i])[::-1][:3])\n",
    "    arr = np.arange(len(doc_topic))[np.argsort(doc_topic[i])][::-1][:3]\n",
    "    print(\"{} (top topic: {})\".format(content_array[i], arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.wsd import lesk\n",
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'technolog', 'can', 'be', 'use', 'to', 'monitor', 'air', 'craft', '.']\n",
      "Synset('monitor.n.05') electronic equipment that is used to check the quality or content of electronic transmissions\n"
     ]
    }
   ],
   "source": [
    "sent = nltk.word_tokenize(content_array[0])\n",
    "print(sent)\n",
    "a = lesk(sent, 'monitor', 'n')\n",
    "print(a, a.definition())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('bank.n.01') sloping land (especially the slope beside a body of water)\n",
      "Synset('depository_financial_institution.n.01') a financial institution that accepts deposits and channels the money into lending activities\n",
      "Synset('bank.n.03') a long ridge or pile\n",
      "Synset('bank.n.04') an arrangement of similar objects in a row or in tiers\n",
      "Synset('bank.n.05') a supply or stock held in reserve for future use (especially in emergencies)\n",
      "Synset('bank.n.06') the funds held by a gambling house or the dealer in some gambling games\n",
      "Synset('bank.n.07') a slope in the turn of a road or track; the outside is higher than the inside in order to reduce the effects of centrifugal force\n",
      "Synset('savings_bank.n.02') a container (usually with a slot in the top) for keeping money at home\n",
      "Synset('bank.n.09') a building in which the business of banking transacted\n",
      "Synset('bank.n.10') a flight maneuver; aircraft tips laterally about its longitudinal axis (especially in turning)\n",
      "Synset('bank.v.01') tip laterally\n",
      "Synset('bank.v.02') enclose with a bank\n",
      "Synset('bank.v.03') do business with a bank or keep an account at a bank\n",
      "Synset('bank.v.04') act as the banker in a game or in gambling\n",
      "Synset('bank.v.05') be in the banking business\n",
      "Synset('deposit.v.02') put into a bank account\n",
      "Synset('bank.v.07') cover with ashes so to control the rate of burning\n",
      "Synset('trust.v.01') have confidence or faith in\n"
     ]
    }
   ],
   "source": [
    "for ss in wn.synsets('bank'):\n",
    "...     print(ss, ss.definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pywsd import disambiguate\n",
    "from pywsd.lesk import simple_lesk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the technolog can be use to monitor air craft .\n",
      "Synset('monitor.n.05') electronic equipment that is used to check the quality or content of electronic transmissions\n"
     ]
    }
   ],
   "source": [
    "sent = content_array[0]\n",
    "print(sent)\n",
    "a = simple_lesk(sent, 'monitor', 'n')\n",
    "print(a, a.definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
